{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\udd2c IRH v68 \u2192 v69 Multi-Agent Verification Pipeline\n",
    "\n",
    "**Purpose:** Comprehensive AI-assisted verification and correction of Intrinsic Resonance Holography v68 manuscript.\n",
    "\n",
    "## Three-Agent Architecture\n",
    "\n",
    "| Agent | Role | Output |\n",
    "|-------|------|--------|\n",
    "| **Agent 1: Analyzer** | Reads v68 at every checkpoint, identifies deficits with exact locations | Structured deficit report (JSON) |\n",
    "| **Agent 2: Resolution** | Receives deficit report, uses code execution for verified calculations, self-reviews | Verified resolutions with calculation logs |\n",
    "| **Agent 3: Integration** | Takes resolutions + manuscript, writes seamlessly, pauses for user approval | IRHv69.md |\n",
    "\n",
    "## Validation Tiers\n",
    "- **Tier 1 (Precision):** Deviations < 0.1% from experimental values\n",
    "- **Tier 2 (Accuracy):** Deviations < 1%\n",
    "- **Tier 3 (Order of Magnitude):** Deviations < 10%\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \u26a0\ufe0f Repository Note\n",
    "\n",
    "**Template Exception:** This notebook is a multi-agent AI verification tool and does not follow the standard 7-cell computational template (Directive 5). It is located in `notebooks/` for convenience but serves a different purpose than the computational notebooks (01_v57_*.ipynb).\n",
    "\n",
    "**v68 Manuscript:** The IRHv68 manuscript (IntrinsicResonanceHolography_v68.md) is not included in this repository. Users should obtain or create this file separately before running this pipeline. This notebook is provided as a verification tool template for future manuscript versions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install required packages\n",
    "!pip install -q google-genai numpy sympy scipy\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from google.colab import userdata, files\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from sympy import *\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Configure Gemini API Client\n",
    "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
    "if not GEMINI_API_KEY:\n",
    "    raise RuntimeError(\n",
    "        \"Missing GEMINI_API_KEY in Colab userdata. \"\n",
    "        \"Set it before running this notebook:\\n\\n\"\n",
    "        \"from google.colab import userdata\\n\"\n",
    "        \"# Then set your key in Colab Secrets\"\n",
    "    )\n",
    "\n",
    "# Create Gemini client\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)\n",
    "\n",
    "print(\"\u2705 Environment configured successfully\")\n",
    "print(f\"\ud83d\udcc5 Session started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload IRH v68 Manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Upload the v68 manuscript\n",
    "print(\"\ud83d\udcc4 Please upload IntrinsicResonanceHolography_v68.md\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Get the uploaded filename\n",
    "MANUSCRIPT_FILENAME = list(uploaded.keys())[0]\n",
    "MANUSCRIPT_CONTENT = uploaded[MANUSCRIPT_FILENAME].decode('utf-8')\n",
    "\n",
    "print(f\"\\n\u2705 Loaded: {MANUSCRIPT_FILENAME}\")\n",
    "print(f\"\ud83d\udcca Total characters: {len(MANUSCRIPT_CONTENT):,}\")\n",
    "print(f\"\ud83d\udcca Total lines: {len(MANUSCRIPT_CONTENT.splitlines()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Manuscript Reader & Parser\n",
    "\n",
    "Parses the v68 manuscript into a structured format with exact location tracking for sections, subsections, and line numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "@dataclass\n",
    "class ManuscriptSection:\n",
    "    \"\"\"Represents a section of the manuscript with location metadata.\"\"\"\n",
    "    section_num: str  # e.g., \"I\", \"II\", \"IX\"\n",
    "    title: str\n",
    "    start_line: int\n",
    "    end_line: int\n",
    "    content: str\n",
    "    subsections: List['ManuscriptSubsection'] = field(default_factory=list)\n",
    "\n",
    "@dataclass\n",
    "class ManuscriptSubsection:\n",
    "    \"\"\"Represents a subsection with location metadata.\"\"\"\n",
    "    number: str  # e.g., \"3.1\", \"9.2\"\n",
    "    title: str\n",
    "    start_line: int\n",
    "    end_line: int\n",
    "    content: str\n",
    "\n",
    "\n",
    "class ManuscriptReader:\n",
    "    \"\"\"Parses IRH manuscript into structured sections with exact line tracking.\"\"\"\n",
    "    \n",
    "    # Chapter patterns for IRH manuscript\n",
    "    CHAPTER_PATTERN = re.compile(\n",
    "        r'^##\\s+(I{1,3}|IV|V|VI{0,3}|IX|X)\\.?\\s+(.+)$',\n",
    "        re.MULTILINE\n",
    "    )\n",
    "    SUBSECTION_PATTERN = re.compile(\n",
    "        r'^###\\s+(\\d+\\.\\d+)\\s+(.+)$',\n",
    "        re.MULTILINE\n",
    "    )\n",
    "    \n",
    "    def __init__(self, content: str):\n",
    "        self.raw_content = content\n",
    "        self.lines = content.splitlines()\n",
    "        self.sections: List[ManuscriptSection] = []\n",
    "        self._parse()\n",
    "    \n",
    "    def _parse(self):\n",
    "        \"\"\"Parse manuscript into sections and subsections.\"\"\"\n",
    "        # Find all chapter headings\n",
    "        chapter_matches = []\n",
    "        for i, line in enumerate(self.lines, start=1):\n",
    "            match = self.CHAPTER_PATTERN.match(line)\n",
    "            if match:\n",
    "                chapter_matches.append((i, match.group(1), match.group(2)))\n",
    "        \n",
    "        # Create sections\n",
    "        for idx, (line_num, num, title) in enumerate(chapter_matches):\n",
    "            # Determine end line\n",
    "            if idx + 1 < len(chapter_matches):\n",
    "                end_line = chapter_matches[idx + 1][0] - 1\n",
    "            else:\n",
    "                end_line = len(self.lines)\n",
    "            \n",
    "            content = '\\\\n'.join(self.lines[line_num - 1:end_line])\n",
    "            section = ManuscriptSection(\n",
    "                section_num=num,\n",
    "                title=title.strip(),\n",
    "                start_line=line_num,\n",
    "                end_line=end_line,\n",
    "                content=content\n",
    "            )\n",
    "            \n",
    "            # Parse subsections within this section\n",
    "            section.subsections = self._parse_subsections(\n",
    "                content, line_num, end_line\n",
    "            )\n",
    "            self.sections.append(section)\n",
    "    \n",
    "    def _parse_subsections(self, content: str, base_line: int, end_line: int) -> List[ManuscriptSubsection]:\n",
    "        \"\"\"Parse subsections within a section.\"\"\"\n",
    "        subsections = []\n",
    "        section_lines = content.splitlines()\n",
    "        \n",
    "        sub_matches = []\n",
    "        for i, line in enumerate(section_lines):\n",
    "            match = self.SUBSECTION_PATTERN.match(line)\n",
    "            if match:\n",
    "                sub_matches.append((i, match.group(1), match.group(2)))\n",
    "        \n",
    "        for idx, (rel_line, num, title) in enumerate(sub_matches):\n",
    "            abs_start = base_line + rel_line\n",
    "            if idx + 1 < len(sub_matches):\n",
    "                abs_end = base_line + sub_matches[idx + 1][0] - 1\n",
    "            else:\n",
    "                abs_end = end_line\n",
    "            \n",
    "            sub_content = '\\\\n'.join(self.lines[abs_start - 1:abs_end])\n",
    "            subsections.append(ManuscriptSubsection(\n",
    "                number=num,\n",
    "                title=title.strip(),\n",
    "                start_line=abs_start,\n",
    "                end_line=abs_end,\n",
    "                content=sub_content\n",
    "            ))\n",
    "        \n",
    "        return subsections\n",
    "    \n",
    "    def get_section(self, section_num: str) -> Optional[ManuscriptSection]:\n",
    "        \"\"\"Get a specific section by Roman numeral.\"\"\"\n",
    "        for section in self.sections:\n",
    "            if section.section_num == section_num:\n",
    "                return section\n",
    "        return None\n",
    "    \n",
    "    def get_lines(self, start: int, end: int) -> str:\n",
    "        \"\"\"Get specific line range (1-indexed, inclusive).\"\"\"\n",
    "        return '\\\\n'.join(self.lines[start - 1:end])\n",
    "    \n",
    "    def get_context_around(self, line: int, context: int = 5) -> Tuple[int, int, str]:\n",
    "        \"\"\"Get context around a specific line.\"\"\"\n",
    "        start = max(1, line - context)\n",
    "        end = min(len(self.lines), line + context)\n",
    "        return start, end, self.get_lines(start, end)\n",
    "    \n",
    "    def summary(self) -> str:\n",
    "        \"\"\"Return a summary of the manuscript structure.\"\"\"\n",
    "        lines = [\"\ud83d\udcda MANUSCRIPT STRUCTURE\\\\n\" + \"=\"*50]\n",
    "        for sec in self.sections:\n",
    "            lines.append(f\"\\\\n## {sec.section_num}. {sec.title}\")\n",
    "            lines.append(f\"   Lines: {sec.start_line}-{sec.end_line}\")\n",
    "            for sub in sec.subsections:\n",
    "                lines.append(f\"   ### {sub.number} {sub.title} (L{sub.start_line}-{sub.end_line})\")\n",
    "        return '\\\\n'.join(lines)\n",
    "\n",
    "\n",
    "# Parse the manuscript\n",
    "manuscript = ManuscriptReader(MANUSCRIPT_CONTENT)\n",
    "print(manuscript.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deficit Report Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "@dataclass\n",
    "class DeficitItem:\n",
    "    \"\"\"A single identified deficit in the manuscript.\"\"\"\n",
    "    id: str\n",
    "    section: str\n",
    "    subsection: Optional[str]\n",
    "    line_range: Tuple[int, int]\n",
    "    issue_type: str  # 'mathematical', 'physical', 'logical', 'notational', 'derivation'\n",
    "    severity: str    # 'critical', 'major', 'minor'\n",
    "    tier: int        # 1, 2, or 3\n",
    "    current_solution: str\n",
    "    why_faulty: str\n",
    "    resolution_path: str\n",
    "    requires_calculation: bool\n",
    "    \n",
    "    def to_dict(self) -> dict:\n",
    "        return {\n",
    "            'id': self.id,\n",
    "            'section': self.section,\n",
    "            'subsection': self.subsection,\n",
    "            'line_range': list(self.line_range),\n",
    "            'issue_type': self.issue_type,\n",
    "            'severity': self.severity,\n",
    "            'tier': self.tier,\n",
    "            'current_solution': self.current_solution,\n",
    "            'why_faulty': self.why_faulty,\n",
    "            'resolution_path': self.resolution_path,\n",
    "            'requires_calculation': self.requires_calculation\n",
    "        }\n",
    "\n",
    "@dataclass\n",
    "class DeficitReport:\n",
    "    \"\"\"Complete deficit analysis report.\"\"\"\n",
    "    manuscript_version: str\n",
    "    analysis_timestamp: str\n",
    "    total_sections_analyzed: int\n",
    "    deficits: List[DeficitItem] = field(default_factory=list)\n",
    "    \n",
    "    def add_deficit(self, item: DeficitItem):\n",
    "        self.deficits.append(item)\n",
    "    \n",
    "    def get_by_severity(self, severity: str) -> List[DeficitItem]:\n",
    "        return [d for d in self.deficits if d.severity == severity]\n",
    "    \n",
    "    def get_requiring_calculation(self) -> List[DeficitItem]:\n",
    "        return [d for d in self.deficits if d.requires_calculation]\n",
    "    \n",
    "    def to_json(self) -> str:\n",
    "        return json.dumps({\n",
    "            'manuscript_version': self.manuscript_version,\n",
    "            'analysis_timestamp': self.analysis_timestamp,\n",
    "            'total_sections_analyzed': self.total_sections_analyzed,\n",
    "            'summary': {\n",
    "                'total_deficits': len(self.deficits),\n",
    "                'critical': len(self.get_by_severity('critical')),\n",
    "                'major': len(self.get_by_severity('major')),\n",
    "                'minor': len(self.get_by_severity('minor')),\n",
    "                'requiring_calculation': len(self.get_requiring_calculation())\n",
    "            },\n",
    "            'deficits': [d.to_dict() for d in self.deficits]\n",
    "        }, indent=2)\n",
    "    \n",
    "    def display_summary(self):\n",
    "        print(\"\\\\n\" + \"=\"*60)\n",
    "        print(\"\ud83d\udccb DEFICIT REPORT SUMMARY\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Manuscript: {self.manuscript_version}\")\n",
    "        print(f\"Analyzed: {self.analysis_timestamp}\")\n",
    "        print(f\"Sections analyzed: {self.total_sections_analyzed}\")\n",
    "        print(f\"\\\\nTotal deficits: {len(self.deficits)}\")\n",
    "        print(f\"  \ud83d\udd34 Critical: {len(self.get_by_severity('critical'))}\")\n",
    "        print(f\"  \ud83d\udfe0 Major: {len(self.get_by_severity('major'))}\")\n",
    "        print(f\"  \ud83d\udfe1 Minor: {len(self.get_by_severity('minor'))}\")\n",
    "        print(f\"  \ud83d\udd22 Requiring calculation: {len(self.get_requiring_calculation())}\")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Resolution:\n",
    "    \"\"\"A verified resolution for a deficit.\"\"\"\n",
    "    deficit_id: str\n",
    "    resolved_content: str\n",
    "    calculation_log: Optional[str]\n",
    "    verification_passed: bool\n",
    "    self_review_notes: str\n",
    "    \n",
    "    def to_dict(self) -> dict:\n",
    "        return {\n",
    "            'deficit_id': self.deficit_id,\n",
    "            'resolved_content': self.resolved_content,\n",
    "            'calculation_log': self.calculation_log,\n",
    "            'verification_passed': self.verification_passed,\n",
    "            'self_review_notes': self.self_review_notes\n",
    "        }\n",
    "\n",
    "print(\"\u2705 Data structures defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# \ud83e\udd16 AGENT 1: Analyzer\n",
    "\n",
    "**Role:** Reads v68 at every checkpoint, produces detailed technical deficit report with exact locations.\n",
    "\n",
    "**Constraints:**\n",
    "- No ad hoc postulates in resolution paths\n",
    "- No circular reasoning\n",
    "- Must specify exact section, subsection, and line ranges\n",
    "- Must explain WHY current solution is faulty\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Shared model name constant for all agents\n",
    "MODEL_NAME = 'gemini-3-pro-preview'\n",
    "\n",
    "def generate_content_with_gemini(prompt: str, system_instruction: str, use_code_execution: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Helper function to generate content using the new google-genai API.\n",
    "    \n",
    "    Args:\n",
    "        prompt: The user prompt/question\n",
    "        system_instruction: The system instruction for the agent\n",
    "        use_code_execution: Whether to enable code execution tool\n",
    "    \n",
    "    Returns:\n",
    "        The generated text response\n",
    "    \"\"\"\n",
    "    # Create contents\n",
    "    contents = [\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[types.Part.from_text(text=prompt)]\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Configure tools\n",
    "    tools = [\n",
    "        types.Tool(url_context=types.UrlContext()),\n",
    "        types.Tool(googleSearch=types.GoogleSearch())\n",
    "    ]\n",
    "    if use_code_execution:\n",
    "        tools.append(types.Tool(code_execution=types.ToolCodeExecution))\n",
    "    \n",
    "    # Configure generation\n",
    "    config = types.GenerateContentConfig(\n",
    "        thinking_config=types.ThinkingConfig(thinking_level=\"HIGH\"),\n",
    "        media_resolution=\"MEDIA_RESOLUTION_HIGH\",\n",
    "        tools=tools,\n",
    "        system_instruction=[types.Part.from_text(text=system_instruction)]\n",
    "    )\n",
    "    \n",
    "    # Generate content with streaming\n",
    "    full_text = \"\"\n",
    "    for chunk in client.models.generate_content_stream(\n",
    "        model=MODEL_NAME,\n",
    "        contents=contents,\n",
    "        config=config\n",
    "    ):\n",
    "        if (chunk.candidates and \n",
    "            chunk.candidates[0].content and \n",
    "            chunk.candidates[0].content.parts):\n",
    "            if chunk.candidates[0].content.parts[0].text:\n",
    "                full_text += chunk.candidates[0].content.parts[0].text\n",
    "    \n",
    "    return full_text\n",
    "\n",
    "\n",
    "\n",
    "class Agent1_Analyzer:\n",
    "    \"\"\"\n",
    "    Agent 1: Constructive Analyzer\n",
    "    \n",
    "    Reads the manuscript at every checkpoint and produces detailed\n",
    "    deficit reports with exact locations.\n",
    "    \"\"\"\n",
    "    \n",
    "    # NOTE: SYSTEM_INSTRUCTION prompts are core agent \"hyperparameters\".\n",
    "    # Version-control and tune these carefully; consider externalizing if they evolve.\n",
    "    SYSTEM_INSTRUCTION = \"\"\"\n",
    "You are the **Constructive Analyzer** for the Intrinsic Resonance Holography (IRH) theory.\n",
    "\n",
    "Your role is to perform rigorous analysis of the manuscript and identify deficits that require correction.\n",
    "\n",
    "**FORMALISM ENFORCEMENT (Directive C):**\n",
    "- Use rigorous gauge theory and fiber bundle terminology exclusively\n",
    "- Describe interactions as \"curvature in the connection\", not \"information exchange\"\n",
    "- Refer to particles as \"resonant modes of the Braid Group B\u2083\", not \"information patterns\"\n",
    "- Use terms like \"holonomy\", \"parallel transport\", \"connection 1-form\", \"field strength 2-form\"\n",
    "\n",
    "## Analysis Framework\n",
    "\n",
    "For each section, you must:\n",
    "1. **Mathematical Verification**: Check all equations, derivations, and numerical results\n",
    "2. **Physical Interpretation**: Verify dimensional consistency and physical meaning\n",
    "3. **Logical Flow**: Identify gaps in reasoning or circular arguments\n",
    "4. **Notational Consistency**: Check symbol usage across the manuscript\n",
    "5. **Comparison to Experiment**: Validate numerical predictions against known values\n",
    "\n",
    "## Validation Tiers\n",
    "- **Tier 1**: Predictions within 0.1% of experimental values (precision regime)\n",
    "- **Tier 2**: Predictions within 1% of experimental values (accuracy regime)\n",
    "- **Tier 3**: Predictions within 10% of experimental values (order of magnitude)\n",
    "\n",
    "## Output Format\n",
    "\n",
    "For each deficit found, provide a JSON object with:\n",
    "```json\n",
    "{\n",
    "  \\\"id\\\": \\\"DEF-SEC-NNN\\\",\n",
    "  \\\"section\\\": \\\"Roman numeral\\\",\n",
    "  \\\"subsection\\\": \\\"X.Y or null\\\",\n",
    "  \\\"line_range\\\": [start, end],\n",
    "  \\\"issue_type\\\": \\\"mathematical|physical|logical|notational|derivation\\\",\n",
    "  \\\"severity\\\": \\\"critical|major|minor\\\",\n",
    "  \\\"tier\\\": 1|2|3,\n",
    "  \\\"current_solution\\\": \\\"What the manuscript currently says\\\",\n",
    "  \\\"why_faulty\\\": \\\"Detailed explanation of the problem\\\",\n",
    "  \\\"resolution_path\\\": \\\"How to fix WITHOUT ad hoc postulates or circular reasoning\\\",\n",
    "  \\\"requires_calculation\\\": true|false\n",
    "}\n",
    "```\n",
    "\n",
    "## Critical Constraints\n",
    "\n",
    "1. **NO AD HOC POSTULATES**: Resolution paths must derive from existing axioms\n",
    "2. **NO CIRCULAR REASONING**: Cannot assume what you're trying to prove\n",
    "3. **EXACT LOCATIONS**: Must specify precise line numbers\n",
    "4. **CONSTRUCTIVE CRITICISM**: Focus on how to improve, not just what's wrong\n",
    "\n",
    "Return your analysis as a JSON array of deficit objects.\n",
    "\"\"\"\n",
    "    \n",
    "    def __init__(self, manuscript: ManuscriptReader):\n",
    "        self.manuscript = manuscript\n",
    "        self.deficit_report = DeficitReport(\n",
    "            manuscript_version='v68',\n",
    "            analysis_timestamp=datetime.now().isoformat(),\n",
    "            total_sections_analyzed=0\n",
    "        )\n",
    "    \n",
    "    def analyze_section(self, section: ManuscriptSection) -> List[DeficitItem]:\n",
    "        \"\"\"Analyze a single section and return deficits found.\"\"\"\n",
    "        print(f\"\\\\n\ud83d\udd2c Analyzing Section {section.section_num}: {section.title}\")\n",
    "        print(f\"   Lines: {section.start_line}-{section.end_line}\")\n",
    "        \n",
    "        # Re-read the full manuscript for context at each checkpoint\n",
    "        full_context = f\"\"\"\n",
    "=== FULL MANUSCRIPT (for reference) ===\n",
    "{self.manuscript.raw_content}\n",
    "\n",
    "=== SECTION TO ANALYZE ===\n",
    "Section: {section.section_num}. {section.title}\n",
    "Lines: {section.start_line} to {section.end_line}\n",
    "\n",
    "{section.content}\n",
    "\n",
    "=== TASK ===\n",
    "Analyze this section for deficits. Return a JSON array of deficit objects.\n",
    "If no deficits are found, return an empty array: []\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            text = generate_content_with_gemini(full_context, self.SYSTEM_INSTRUCTION, use_code_execution=False)\n",
    "            \n",
    "            # Parse JSON from response\n",
    "            # Extract JSON array\n",
    "            json_match = re.search(r'\\\\[.*?\\\\]', text, re.DOTALL)\n",
    "            if json_match:\n",
    "                deficits_data = json.loads(json_match.group())\n",
    "            else:\n",
    "                print(f\"   \u2139\ufe0f No deficits found in section {section.section_num}\")\n",
    "                return []\n",
    "            \n",
    "            deficits = []\n",
    "            for d in deficits_data:\n",
    "                item = DeficitItem(\n",
    "                    id=d.get('id', f'DEF-{section.section_num}-{len(deficits)+1:03d}'),\n",
    "                    section=d.get('section', section.section_num),\n",
    "                    subsection=d.get('subsection'),\n",
    "                    line_range=tuple(d.get('line_range', [section.start_line, section.end_line])),\n",
    "                    issue_type=d.get('issue_type', 'unknown'),\n",
    "                    severity=d.get('severity', 'minor'),\n",
    "                    tier=d.get('tier', 3),\n",
    "                    current_solution=d.get('current_solution', ''),\n",
    "                    why_faulty=d.get('why_faulty', ''),\n",
    "                    resolution_path=d.get('resolution_path', ''),\n",
    "                    requires_calculation=d.get('requires_calculation', False)\n",
    "                )\n",
    "                deficits.append(item)\n",
    "                self.deficit_report.add_deficit(item)\n",
    "            \n",
    "            print(f\"   \u2705 Found {len(deficits)} deficit(s)\")\n",
    "            return deficits\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   \u274c Error analyzing section: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def run_full_analysis(self) -> DeficitReport:\n",
    "        \"\"\"Run analysis on all sections.\"\"\"\n",
    "        print(\"\\\\n\" + \"=\"*60)\n",
    "        print(\"\ud83d\ude80 AGENT 1: Starting Full Manuscript Analysis\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for section in self.manuscript.sections:\n",
    "            self.analyze_section(section)\n",
    "            self.deficit_report.total_sections_analyzed += 1\n",
    "            time.sleep(1)  # Rate limiting\n",
    "        \n",
    "        self.deficit_report.display_summary()\n",
    "        return self.deficit_report\n",
    "\n",
    "\n",
    "# Initialize Agent 1\n",
    "agent1 = Agent1_Analyzer(manuscript)\n",
    "print(\"\u2705 Agent 1 (Analyzer) initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Agent 1 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Run the full analysis\n",
    "deficit_report = agent1.run_full_analysis()\n",
    "\n",
    "# Save intermediate artifact\n",
    "with open('deficit_report_v68.json', 'w') as f:\n",
    "    f.write(deficit_report.to_json())\n",
    "\n",
    "print(\"\\\\n\ud83d\udcc1 Saved: deficit_report_v68.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display detailed deficits\n",
    "print(\"\\\\n\" + \"=\"*60)\n",
    "print(\"\ud83d\udccb DETAILED DEFICIT LIST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for i, d in enumerate(deficit_report.deficits, 1):\n",
    "    severity_icon = {'critical': '\ud83d\udd34', 'major': '\ud83d\udfe0', 'minor': '\ud83d\udfe1'}.get(d.severity, '\u26aa')\n",
    "    print(f\"\\\\n{severity_icon} [{d.id}] {d.issue_type.upper()}\")\n",
    "    print(f\"   Section: {d.section}\" + (f\" / {d.subsection}\" if d.subsection else \"\"))\n",
    "    print(f\"   Lines: {d.line_range[0]}-{d.line_range[1]}\")\n",
    "    print(f\"   Severity: {d.severity} | Tier: {d.tier}\")\n",
    "    print(f\"   Current: {d.current_solution[:100]}...\" if len(d.current_solution) > 100 else f\"   Current: {d.current_solution}\")\n",
    "    print(f\"   Problem: {d.why_faulty[:150]}...\" if len(d.why_faulty) > 150 else f\"   Problem: {d.why_faulty}\")\n",
    "    print(f\"   Resolution: {d.resolution_path[:150]}...\" if len(d.resolution_path) > 150 else f\"   Resolution: {d.resolution_path}\")\n",
    "    if d.requires_calculation:\n",
    "        print(\"   \ud83d\udd22 Requires verified calculation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# \ud83d\udd27 AGENT 2: Resolution Agent\n",
    "\n",
    "**Role:** Receives manuscript + deficit report, uses code execution for verified calculations, self-reviews work.\n",
    "\n",
    "**Capabilities:**\n",
    "- Code execution for numerical verification\n",
    "- Symbolic mathematics with SymPy\n",
    "- Self-review before submitting resolutions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class Agent2_Resolution:\n",
    "    \"\"\"\n",
    "    Agent 2: Resolution Agent\n",
    "    \n",
    "    Receives deficit report, generates verified resolutions using\n",
    "    code execution, and performs self-review.\n",
    "    \"\"\"\n",
    "    \n",
    "    # NOTE: SYSTEM_INSTRUCTION prompts are core agent \"hyperparameters\".\n",
    "    # Version-control and tune these carefully; consider externalizing if they evolve.\n",
    "    SYSTEM_INSTRUCTION = \"\"\"\n",
    "You are the **Resolution Agent** for the Intrinsic Resonance Holography (IRH) theory.\n",
    "\n",
    "Your role is to generate verified resolutions for identified deficits.\n",
    "\n",
    "**CRITICAL DIRECTIVE A (NO HARDCODED EXPERIMENTAL VALUES):**\n",
    "- ALL physical quantities MUST be derived directly from theory\n",
    "- Experimental values can ONLY be used for final validation/comparison\n",
    "- Any experimental values MUST be labeled \"FOR VALIDATION ONLY\"\n",
    "- NEVER use experimental values as inputs to theoretical calculations\n",
    "\n",
    "**FORMALISM ENFORCEMENT (Directive C):**\n",
    "- Use rigorous gauge theory and fiber bundle terminology exclusively\n",
    "- Describe interactions as \"curvature in the connection\", not \"information exchange\"\n",
    "- Refer to particles as \"resonant modes of the Braid Group B\u2083\"\n",
    "- Avoid information-theoretic metaphors except for holographic boundary entropy\n",
    "\n",
    "## Resolution Process\n",
    "\n",
    "For each deficit:\n",
    "1. **Understand Context**: Read the full manuscript section where the deficit occurs\n",
    "2. **Verify the Problem**: Confirm the deficit analysis is correct\n",
    "3. **Generate Resolution**: Create corrected content that fixes the issue\n",
    "4. **Execute Calculations**: For mathematical deficits, provide Python code to verify\n",
    "5. **Self-Review**: Check your resolution before submitting\n",
    "\n",
    "## Code Execution Guidelines\n",
    "\n",
    "When calculations are needed, provide executable Python code using:\n",
    "- `numpy` for numerical computation\n",
    "- `sympy` for symbolic mathematics\n",
    "- `scipy` for scientific functions\n",
    "\n",
    "## Output Format\n",
    "\n",
    "For each resolution, provide:\n",
    "```json\n",
    "{\n",
    "  \\\"deficit_id\\\": \\\"DEF-XXX-NNN\\\",\n",
    "  \\\"resolved_content\\\": \\\"The corrected text/equations to replace the faulty content\\\",\n",
    "  \\\"calculation_code\\\": \\\"Python code to verify (if applicable)\\\",\n",
    "  \\\"calculation_result\\\": \\\"Expected output from the code\\\",\n",
    "  \\\"self_review\\\": {\n",
    "    \\\"mathematically_sound\\\": true|false,\n",
    "    \\\"no_ad_hoc\\\": true|false,\n",
    "    \\\"no_circular_reasoning\\\": true|false,\n",
    "    \\\"dimensionally_consistent\\\": true|false,\n",
    "    \\\"notes\\\": \\\"Any additional review notes\\\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "## Critical Constraints\n",
    "\n",
    "1. All calculations must be VERIFIED with actual code execution\n",
    "2. No hand-wavy approximations without explicit justification\n",
    "3. Maintain the manuscript's notation and style\n",
    "4. Preserve the logical flow of the argument\n",
    "\"\"\"\n",
    "\n",
    "    def __init__(self, manuscript: ManuscriptReader, deficit_report: DeficitReport):\n",
    "        self.manuscript = manuscript\n",
    "        self.deficit_report = deficit_report\n",
    "        self.resolutions: List[Resolution] = []\n",
    "    \n",
    "    def resolve_deficit(self, deficit: DeficitItem) -> Optional[Resolution]:\n",
    "        \"\"\"Generate a verified resolution for a single deficit.\"\"\"\n",
    "        print(f\"\\\\n\ud83d\udd27 Resolving [{deficit.id}]: {deficit.issue_type}\")\n",
    "        print(f\"   Section: {deficit.section}, Lines: {deficit.line_range}\")\n",
    "        \n",
    "        # Get relevant manuscript context\n",
    "        section = self.manuscript.get_section(deficit.section)\n",
    "        if not section:\n",
    "            print(f\"   \u274c Could not find section {deficit.section}\")\n",
    "            return None\n",
    "        \n",
    "        # Get the specific lines\n",
    "        context_start = max(1, deficit.line_range[0] - 10)\n",
    "        context_end = min(len(self.manuscript.lines), deficit.line_range[1] + 10)\n",
    "        local_context = self.manuscript.get_lines(context_start, context_end)\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "=== FULL MANUSCRIPT (for reference) ===\n",
    "{self.manuscript.raw_content}\n",
    "\n",
    "=== DEFICIT TO RESOLVE ===\n",
    "{json.dumps(deficit.to_dict(), indent=2)}\n",
    "\n",
    "=== LOCAL CONTEXT (Lines {context_start}-{context_end}) ===\n",
    "{local_context}\n",
    "\n",
    "=== TASK ===\n",
    "Generate a verified resolution for this deficit.\n",
    "{\"Use code execution to verify any calculations.\" if deficit.requires_calculation else \"\"}\n",
    "\n",
    "Return your resolution as a JSON object.\n",
    "\"\"\"\n",
    "        \n",
    "        try:\n",
    "            text = generate_content_with_gemini(prompt, self.SYSTEM_INSTRUCTION, use_code_execution=True)\n",
    "            \n",
    "            # Extract resolution from response\n",
    "            json_match = re.search(r'\\\\{.*?\\\\}', text, re.DOTALL)\n",
    "            \n",
    "            if json_match:\n",
    "                resolution_data = json.loads(json_match.group())\n",
    "            else:\n",
    "                print(f\"   \u26a0\ufe0f Could not parse resolution JSON\")\n",
    "                # Use the raw response as resolution\n",
    "                resolution_data = {\n",
    "                    'resolved_content': text,\n",
    "                    'self_review': {'notes': 'Auto-extracted from response'}\n",
    "                }\n",
    "            \n",
    "            # Extract calculation log from code execution\n",
    "            calc_log = None\n",
    "            if hasattr(response, 'candidates') and response.candidates:\n",
    "                for part in response.candidates[0].content.parts:\n",
    "                    if hasattr(part, 'executable_code'):\n",
    "                        calc_log = part.executable_code.code\n",
    "                    if hasattr(part, 'code_execution_result'):\n",
    "                        if calc_log:\n",
    "                            calc_log += f\"\\\\n\\\\n# Output:\\\\n{part.code_execution_result.output}\"\n",
    "            \n",
    "            # Determine verification status\n",
    "            self_review = resolution_data.get('self_review', {})\n",
    "            verification_passed = all([\n",
    "                self_review.get('mathematically_sound', True),\n",
    "                self_review.get('no_ad_hoc', True),\n",
    "                self_review.get('no_circular_reasoning', True),\n",
    "                self_review.get('dimensionally_consistent', True)\n",
    "            ])\n",
    "            \n",
    "            resolution = Resolution(\n",
    "                deficit_id=deficit.id,\n",
    "                resolved_content=resolution_data.get('resolved_content', ''),\n",
    "                calculation_log=calc_log,\n",
    "                verification_passed=verification_passed,\n",
    "                self_review_notes=json.dumps(self_review)\n",
    "            )\n",
    "            \n",
    "            self.resolutions.append(resolution)\n",
    "            \n",
    "            status = \"\u2705 PASSED\" if verification_passed else \"\u26a0\ufe0f NEEDS REVIEW\"\n",
    "            print(f\"   {status}\")\n",
    "            \n",
    "            return resolution\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   \u274c Error resolving deficit: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def run_all_resolutions(self) -> List[Resolution]:\n",
    "        \"\"\"Resolve all deficits in the report.\"\"\"\n",
    "        print(\"\\\\n\" + \"=\"*60)\n",
    "        print(\"\ud83d\ude80 AGENT 2: Starting Resolution Process\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Prioritize by severity\n",
    "        sorted_deficits = sorted(\n",
    "            self.deficit_report.deficits,\n",
    "            key=lambda d: {'critical': 0, 'major': 1, 'minor': 2}.get(d.severity, 3)\n",
    "        )\n",
    "        \n",
    "        # Configurable exponential backoff for pacing/API rate limiting\n",
    "        import os\n",
    "        base_delay = float(os.getenv(\"GEMINI_RATE_LIMIT_BASE_DELAY_SECONDS\", \"1.0\"))\n",
    "        max_delay = float(os.getenv(\"GEMINI_RATE_LIMIT_MAX_DELAY_SECONDS\", \"8.0\"))\n",
    "        current_delay = base_delay\n",
    "        \n",
    "        for deficit in sorted_deficits:\n",
    "            self.resolve_deficit(deficit)\n",
    "            # Exponential backoff between resolutions to help respect API rate limits\n",
    "            if current_delay > 0:\n",
    "                time.sleep(current_delay)\n",
    "                current_delay = min(current_delay * 2, max_delay)\n",
    "        \n",
    "        # Summary\n",
    "        passed = sum(1 for r in self.resolutions if r.verification_passed)\n",
    "        print(f\"\\\\n\" + \"=\"*60)\n",
    "        print(f\"\ud83d\udcca Resolution Summary: {passed}/{len(self.resolutions)} verified\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        return self.resolutions\n",
    "\n",
    "\n",
    "# Initialize Agent 2 (requires deficit report from Agent 1)\n",
    "print(\"\u2705 Agent 2 (Resolution) class defined\")\n",
    "print(\"   Run after Agent 1 completes analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Agent 2 Resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize and run Agent 2\n",
    "agent2 = Agent2_Resolution(manuscript, deficit_report)\n",
    "resolutions = agent2.run_all_resolutions()\n",
    "\n",
    "# Save intermediate artifact\n",
    "with open('resolutions_v68.json', 'w') as f:\n",
    "    json.dump([r.to_dict() for r in resolutions], f, indent=2)\n",
    "\n",
    "print(\"\\\\n\ud83d\udcc1 Saved: resolutions_v68.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display resolution details\n",
    "print(\"\\\\n\" + \"=\"*60)\n",
    "print(\"\ud83d\udccb RESOLUTION DETAILS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for r in resolutions:\n",
    "    status = \"\u2705\" if r.verification_passed else \"\u26a0\ufe0f\"\n",
    "    print(f\"\\\\n{status} [{r.deficit_id}]\")\n",
    "    print(f\"   Content preview: {r.resolved_content[:200]}...\" if len(r.resolved_content) > 200 else f\"   Content: {r.resolved_content}\")\n",
    "    if r.calculation_log:\n",
    "        print(f\"   \ud83d\udcca Calculation verified with code execution\")\n",
    "    print(f\"   Self-review: {r.self_review_notes[:100]}...\" if len(r.self_review_notes) > 100 else f\"   Self-review: {r.self_review_notes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# \ud83d\udd00 AGENT 3: Integration Agent\n",
    "\n",
    "**Role:** Takes resolutions + report + manuscript, writes seamlessly into updated paper.\n",
    "\n",
    "**Workflow:**\n",
    "1. Apply resolutions to manuscript\n",
    "2. Ensure seamless integration\n",
    "3. **PAUSE for user approval**\n",
    "4. Output IRHv69.md\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class Agent3_Integration:\n",
    "    \"\"\"\n",
    "    Agent 3: Integration Agent\n",
    "    \n",
    "    Takes resolutions and integrates them seamlessly into the manuscript.\n",
    "    Pauses for user approval before finalizing.\n",
    "    \"\"\"\n",
    "    \n",
    "    # NOTE: SYSTEM_INSTRUCTION prompts are core agent \"hyperparameters\".\n",
    "    # Version-control and tune these carefully; consider externalizing if they evolve.\n",
    "    SYSTEM_INSTRUCTION = \"\"\"\n",
    "You are the **Integration Agent** for the Intrinsic Resonance Holography (IRH) theory.\n",
    "\n",
    "Your role is to integrate verified resolutions seamlessly into the manuscript.\n",
    "\n",
    "**FORMALISM ENFORCEMENT (Directive C):**\n",
    "- Maintain rigorous gauge theory and fiber bundle terminology throughout\n",
    "- Ensure integrated text uses proper formalism consistently\n",
    "\n",
    "## Integration Guidelines\n",
    "\n",
    "1. **Preserve Voice**: Maintain the manuscript's academic writing style\n",
    "2. **Smooth Transitions**: Ensure edits flow naturally with surrounding text\n",
    "3. **Notation Consistency**: Use the same symbols and conventions throughout\n",
    "4. **Cross-References**: Update any references to changed content\n",
    "5. **Version Clarity**: The output is v69, building on v68\n",
    "\n",
    "## Output Format\n",
    "\n",
    "Return the complete updated manuscript with all resolutions integrated.\n",
    "Mark significant changes with HTML comments: <!-- v69: [description] -->\n",
    "\n",
    "## Quality Checks\n",
    "\n",
    "Before finalizing, verify:\n",
    "- All deficits have been addressed\n",
    "- No orphaned references\n",
    "- Consistent equation numbering\n",
    "- Proper section/subsection structure maintained\n",
    "\"\"\"\n",
    "\n",
    "    def __init__(self, manuscript: ManuscriptReader, deficit_report: DeficitReport, resolutions: List[Resolution]):\n",
    "        self.manuscript = manuscript\n",
    "        self.deficit_report = deficit_report\n",
    "        self.resolutions = resolutions\n",
    "        self.updated_manuscript = None\n",
    "        self.change_log = []\n",
    "    \n",
    "    def prepare_integration_prompt(self) -> str:\n",
    "        \"\"\"Prepare the prompt for integration.\"\"\"\n",
    "        resolution_summary = []\n",
    "        for r in self.resolutions:\n",
    "            # Find matching deficit\n",
    "            deficit = next((d for d in self.deficit_report.deficits if d.id == r.deficit_id), None)\n",
    "            if deficit:\n",
    "                resolution_summary.append({\n",
    "                    'deficit_id': r.deficit_id,\n",
    "                    'section': deficit.section,\n",
    "                    'subsection': deficit.subsection,\n",
    "                    'line_range': deficit.line_range,\n",
    "                    'original_issue': deficit.current_solution,\n",
    "                    'resolved_content': r.resolved_content,\n",
    "                    'verified': r.verification_passed\n",
    "                })\n",
    "        \n",
    "        return f\"\"\"\n",
    "=== ORIGINAL MANUSCRIPT (v68) ===\n",
    "{self.manuscript.raw_content}\n",
    "\n",
    "=== RESOLUTIONS TO INTEGRATE ===\n",
    "{json.dumps(resolution_summary, indent=2)}\n",
    "\n",
    "=== TASK ===\n",
    "Integrate all resolutions into the manuscript to create v69.\n",
    "Return the COMPLETE updated manuscript with all changes applied.\n",
    "Use <!-- v69: description --> comments to mark significant changes.\n",
    "\"\"\"\n",
    "    \n",
    "    def generate_updated_manuscript(self) -> str:\n",
    "        \"\"\"Generate the updated manuscript with all resolutions integrated.\"\"\"\n",
    "        print(\"\\\\n\" + \"=\"*60)\n",
    "        print(\"\ud83d\ude80 AGENT 3: Starting Integration Process\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        print(f\"\\\\n\ud83d\udcdd Integrating {len(self.resolutions)} resolution(s)...\")\n",
    "        \n",
    "        prompt = self.prepare_integration_prompt()\n",
    "        \n",
    "        try:\n",
    "            text = generate_content_with_gemini(prompt, self.SYSTEM_INSTRUCTION, use_code_execution=False)\n",
    "            self.updated_manuscript = response.text\n",
    "            \n",
    "            # Log changes\n",
    "            for r in self.resolutions:\n",
    "                self.change_log.append({\n",
    "                    'deficit_id': r.deficit_id,\n",
    "                    'verified': r.verification_passed\n",
    "                })\n",
    "            \n",
    "            print(f\"\\\\n\u2705 Integration complete\")\n",
    "            print(f\"   Original length: {len(self.manuscript.raw_content):,} chars\")\n",
    "            print(f\"   Updated length: {len(self.updated_manuscript):,} chars\")\n",
    "            \n",
    "            return self.updated_manuscript\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\\\n\u274c Error during integration: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def display_preview(self, lines: int = 100):\n",
    "        \"\"\"Display a preview of the updated manuscript.\"\"\"\n",
    "        if not self.updated_manuscript:\n",
    "            print(\"\u26a0\ufe0f No updated manuscript available. Run generate_updated_manuscript() first.\")\n",
    "            return\n",
    "        \n",
    "        preview_lines = self.updated_manuscript.splitlines()[:lines]\n",
    "        print(\"\\\\n\" + \"=\"*60)\n",
    "        print(f\"\ud83d\udcc4 PREVIEW (first {lines} lines)\")\n",
    "        print(\"=\"*60 + \"\\\\n\")\n",
    "        print('\\\\n'.join(preview_lines))\n",
    "        print(\"\\\\n\" + \"=\"*60)\n",
    "        print(f\"... [{len(self.updated_manuscript.splitlines()) - lines} more lines]\")\n",
    "\n",
    "\n",
    "# Initialize Agent 3 (requires resolutions from Agent 2)\n",
    "print(\"\u2705 Agent 3 (Integration) class defined\")\n",
    "print(\"   Run after Agent 2 completes resolutions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Agent 3 Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize and run Agent 3\n",
    "agent3 = Agent3_Integration(manuscript, deficit_report, resolutions)\n",
    "updated_manuscript = agent3.generate_updated_manuscript()\n",
    "\n",
    "# Show preview\n",
    "agent3.display_preview(lines=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# \u23f8\ufe0f USER APPROVAL CHECKPOINT\n",
    "\n",
    "**Before saving IRHv69.md, please review the changes and approve.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display change summary for user review\n",
    "print(\"\\\\n\" + \"=\"*60)\n",
    "print(\"\ud83d\udccb CHANGE SUMMARY FOR APPROVAL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\\\n\ud83d\udcca Statistics:\")\n",
    "print(f\"   Deficits identified: {len(deficit_report.deficits)}\")\n",
    "print(f\"   Resolutions generated: {len(resolutions)}\")\n",
    "verified = sum(1 for r in resolutions if r.verification_passed)\n",
    "print(f\"   Verified resolutions: {verified}/{len(resolutions)}\")\n",
    "\n",
    "print(f\"\\\\n\ud83d\udcdd Changes by section:\")\n",
    "sections_changed = {}\n",
    "for d in deficit_report.deficits:\n",
    "    sections_changed[d.section] = sections_changed.get(d.section, 0) + 1\n",
    "for sec, count in sorted(sections_changed.items()):\n",
    "    print(f\"   Section {sec}: {count} change(s)\")\n",
    "\n",
    "print(f\"\\\\n\u26a0\ufe0f Unverified resolutions:\")\n",
    "unverified = [r for r in resolutions if not r.verification_passed]\n",
    "if unverified:\n",
    "    for r in unverified:\n",
    "        print(f\"   - {r.deficit_id}\")\n",
    "else:\n",
    "    print(\"   None - all resolutions verified! \u2705\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# USER APPROVAL CHECKPOINT\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"\\\\n\" + \"\ud83d\udd14\"*20)\n",
    "print(\"\\\\n\u23f8\ufe0f  USER APPROVAL REQUIRED\")\n",
    "print(\"\\\\nReview the changes above. Do you want to save IRHv69.md?\")\n",
    "print(\"\\\\n\" + \"\ud83d\udd14\"*20 + \"\\\\n\")\n",
    "\n",
    "# Capture approver identity for audit logging\n",
    "approver_id = input(\"Enter your username or identifier for audit logging (or press Enter for anonymous): \").strip()\n",
    "if not approver_id:\n",
    "    approver_id = \"anonymous\"\n",
    "\n",
    "# Prompt for approval decision\n",
    "approval = input(\"Type 'yes' to approve and save, or 'no' to cancel: \").strip().lower()\n",
    "approval_timestamp = datetime.utcnow().isoformat() + \"Z\"\n",
    "\n",
    "if approval == 'yes':\n",
    "    APPROVED = True\n",
    "    APPROVAL_METADATA = {\n",
    "        \"user\": approver_id,\n",
    "        \"timestamp\": approval_timestamp,\n",
    "        \"decision\": \"approved\"\n",
    "    }\n",
    "    print(f\"\\\\n\u2705 APPROVED by {approver_id} at {approval_timestamp}\")\n",
    "    print(\"Proceeding to save IRHv69.md\")\n",
    "else:\n",
    "    APPROVED = False\n",
    "    APPROVAL_METADATA = {\n",
    "        \"user\": approver_id,\n",
    "        \"timestamp\": approval_timestamp,\n",
    "        \"decision\": \"declined\"\n",
    "    }\n",
    "    print(f\"\\\\n\u274c DECLINED by {approver_id} at {approval_timestamp}\")\n",
    "    print(\"IRHv69.md will NOT be saved\")\n",
    "    print(\"You can re-run the integration or make manual adjustments.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# \ud83d\udcbe Export IRHv69.md\n",
    "\n",
    "**Only runs if user approved in the previous cell.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "if APPROVED:\n",
    "    # Save the updated manuscript\n",
    "    output_filename = 'IntrinsicResonanceHolography_v69.md'\n",
    "    \n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(updated_manuscript)\n",
    "    \n",
    "    print(f\"\\\\n\u2705 Saved: {output_filename}\")\n",
    "    print(f\"   Size: {len(updated_manuscript):,} characters\")\n",
    "    print(f\"   Lines: {len(updated_manuscript.splitlines()):,}\")\n",
    "    \n",
    "    # Also save the full pipeline artifacts\n",
    "    pipeline_summary = {\n",
    "        'version': 'v68 \u2192 v69',\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'deficits_found': len(deficit_report.deficits),\n",
    "        'resolutions_generated': len(resolutions),\n",
    "        'resolutions_verified': verified,\n",
    "        'sections_modified': list(sections_changed.keys()),\n",
    "        'approved': True\n",
    "    }\n",
    "    \n",
    "    with open('v69_pipeline_summary.json', 'w') as f:\n",
    "        json.dump(pipeline_summary, f, indent=2)\n",
    "    \n",
    "    print(f\"\\\\n\ud83d\udcc1 Pipeline summary saved: v69_pipeline_summary.json\")\n",
    "    \n",
    "    # Download files\n",
    "    print(\"\\\\n\ud83d\udce5 Downloading files...\")\n",
    "    files.download(output_filename)\n",
    "    files.download('deficit_report_v68.json')\n",
    "    files.download('resolutions_v68.json')\n",
    "    files.download('v69_pipeline_summary.json')\n",
    "    \n",
    "    print(\"\\\\n\ud83c\udf89 Pipeline complete! All files downloaded.\")\n",
    "else:\n",
    "    print(\"\\\\n\u23f8\ufe0f Export skipped - user did not approve.\")\n",
    "    print(\"   Re-run the approval cell when ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# \ud83d\udcca Optional: Detailed Analysis Reports\n",
    "\n",
    "Additional analysis and visualization tools.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Deficit distribution by type and severity\n",
    "print(\"\\\\n\" + \"=\"*60)\n",
    "print(\"\ud83d\udcca DEFICIT ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# By type\n",
    "by_type = {}\n",
    "for d in deficit_report.deficits:\n",
    "    by_type[d.issue_type] = by_type.get(d.issue_type, 0) + 1\n",
    "\n",
    "print(\"\\\\nBy Issue Type:\")\n",
    "for t, count in sorted(by_type.items(), key=lambda x: -x[1]):\n",
    "    bar = '\u2588' * count\n",
    "    print(f\"  {t:15} {bar} ({count})\")\n",
    "\n",
    "# By tier\n",
    "by_tier = {}\n",
    "for d in deficit_report.deficits:\n",
    "    by_tier[d.tier] = by_tier.get(d.tier, 0) + 1\n",
    "\n",
    "print(\"\\\\nBy Validation Tier:\")\n",
    "tier_labels = {1: 'Tier 1 (<0.1%)', 2: 'Tier 2 (<1%)', 3: 'Tier 3 (<10%)'}\n",
    "for t in [1, 2, 3]:\n",
    "    count = by_tier.get(t, 0)\n",
    "    bar = '\u2588' * count\n",
    "    print(f\"  {tier_labels[t]:15} {bar} ({count})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Show calculation logs from verified resolutions\n",
    "print(\"\\\\n\" + \"=\"*60)\n",
    "print(\"\ud83d\udd22 CALCULATION LOGS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for r in resolutions:\n",
    "    if r.calculation_log:\n",
    "        print(f\"\\\\n--- {r.deficit_id} ---\")\n",
    "        print(r.calculation_log[:500])\n",
    "        if len(r.calculation_log) > 500:\n",
    "            print(f\"... [{len(r.calculation_log) - 500} more characters]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83d\udcdd Session Notes\n",
    "\n",
    "**Pipeline Version:** 1.0  \n",
    "**Target Repository:** brandonmccraryresearch-cloud/IRHV24  \n",
    "**Notebook for PR:** IRHv68_MultiAgent_Verification.ipynb\n",
    "\n",
    "### Changelog\n",
    "- v1.0: Initial three-agent architecture (Analyzer \u2192 Resolution \u2192 Integration)\n",
    "\n",
    "---"
   ]
  }
 ]
}