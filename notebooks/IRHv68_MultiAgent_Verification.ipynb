{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üî¨ IRH v68 ‚Üí v69 Multi-Agent Verification Pipeline\n",
        "\n",
        "**Purpose:** Comprehensive AI-assisted verification and correction of Intrinsic Resonance Holography v68 manuscript.\n",
        "\n",
        "## Three-Agent Architecture\n",
        "\n",
        "| Agent | Role | Output |\n",
        "|-------|------|--------|\n",
        "| **Agent 1: Analyzer** | Reads v68 at every checkpoint, identifies deficits with exact locations | Structured deficit report (JSON) |\n",
        "| **Agent 2: Resolution** | Receives deficit report, uses code execution for verified calculations, self-reviews | Verified resolutions with calculation logs |\n",
        "| **Agent 3: Integration** | Takes resolutions + manuscript, writes seamlessly, pauses for user approval | IRHv69.md |\n",
        "\n",
        "## Validation Tiers\n",
        "- **Tier 1 (Precision):** Deviations < 0.1% from experimental values\n",
        "- **Tier 2 (Accuracy):** Deviations < 1%\n",
        "- **Tier 3 (Order of Magnitude):** Deviations < 10%\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Install required packages\n",
        "!pip install -q google-generativeai numpy sympy scipy\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata, files\n",
        "import json\n",
        "import re\n",
        "import numpy as np\n",
        "from sympy import *\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Dict, Optional, Tuple\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "# Configure Gemini API\n",
        "GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "print(\"‚úÖ Environment configured successfully\")\n",
        "print(f\"üìÖ Session started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Upload IRH v68 Manuscript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Upload the v68 manuscript\n",
        "print(\"üìÑ Please upload IntrinsicResonanceHolography_v68.md\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the uploaded filename\n",
        "MANUSCRIPT_FILENAME = list(uploaded.keys())[0]\n",
        "MANUSCRIPT_CONTENT = uploaded[MANUSCRIPT_FILENAME].decode('utf-8')\n",
        "\n",
        "print(f\"\\n‚úÖ Loaded: {MANUSCRIPT_FILENAME}\")\n",
        "print(f\"üìä Total characters: {len(MANUSCRIPT_CONTENT):,}\")\n",
        "print(f\"üìä Total lines: {len(MANUSCRIPT_CONTENT.splitlines()):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Manuscript Reader & Parser\n",
        "\n",
        "Parses the v68 manuscript into a structured format with exact location tracking for sections, subsections, and line numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "@dataclass\n",
        "class ManuscriptSection:\n",
        "    \"\"\"Represents a section of the manuscript with location metadata.\"\"\"\n",
        "    section_num: str  # e.g., \"I\", \"II\", \"IX\"\n",
        "    title: str\n",
        "    start_line: int\n",
        "    end_line: int\n",
        "    content: str\n",
        "    subsections: List['ManuscriptSubsection'] = field(default_factory=list)\n",
        "\n",
        "@dataclass\n",
        "class ManuscriptSubsection:\n",
        "    \"\"\"Represents a subsection with location metadata.\"\"\"\n",
        "    number: str  # e.g., \"3.1\", \"9.2\"\n",
        "    title: str\n",
        "    start_line: int\n",
        "    end_line: int\n",
        "    content: str\n",
        "\n",
        "\n",
        "class ManuscriptReader:\n",
        "    \"\"\"Parses IRH manuscript into structured sections with exact line tracking.\"\"\"\n",
        "    \n",
        "    # Chapter patterns for IRH manuscript\n",
        "    CHAPTER_PATTERN = re.compile(\n",
        "        r'^##\\\\s+(I{1,3}|IV|V|VI{0,3}|IX|X)\\\\.?\\\\s+(.+)$',\n",
        "        re.MULTILINE\n",
        "    )\n",
        "    SUBSECTION_PATTERN = re.compile(\n",
        "        r'^###\\\\s+(\\\\d+\\\\.\\\\d+)\\\\s+(.+)$',\n",
        "        re.MULTILINE\n",
        "    )\n",
        "    \n",
        "    def __init__(self, content: str):\n",
        "        self.raw_content = content\n",
        "        self.lines = content.splitlines()\n",
        "        self.sections: List[ManuscriptSection] = []\n",
        "        self._parse()\n",
        "    \n",
        "    def _parse(self):\n",
        "        \"\"\"Parse manuscript into sections and subsections.\"\"\"\n",
        "        # Find all chapter headings\n",
        "        chapter_matches = []\n",
        "        for i, line in enumerate(self.lines, start=1):\n",
        "            match = self.CHAPTER_PATTERN.match(line)\n",
        "            if match:\n",
        "                chapter_matches.append((i, match.group(1), match.group(2)))\n",
        "        \n",
        "        # Create sections\n",
        "        for idx, (line_num, num, title) in enumerate(chapter_matches):\n",
        "            # Determine end line\n",
        "            if idx + 1 < len(chapter_matches):\n",
        "                end_line = chapter_matches[idx + 1][0] - 1\n",
        "            else:\n",
        "                end_line = len(self.lines)\n",
        "            \n",
        "            content = '\\\\n'.join(self.lines[line_num - 1:end_line])\n",
        "            section = ManuscriptSection(\n",
        "                section_num=num,\n",
        "                title=title.strip(),\n",
        "                start_line=line_num,\n",
        "                end_line=end_line,\n",
        "                content=content\n",
        "            )\n",
        "            \n",
        "            # Parse subsections within this section\n",
        "            section.subsections = self._parse_subsections(\n",
        "                content, line_num, end_line\n",
        "            )\n",
        "            self.sections.append(section)\n",
        "    \n",
        "    def _parse_subsections(self, content: str, base_line: int, end_line: int) -> List[ManuscriptSubsection]:\n",
        "        \"\"\"Parse subsections within a section.\"\"\"\n",
        "        subsections = []\n",
        "        section_lines = content.splitlines()\n",
        "        \n",
        "        sub_matches = []\n",
        "        for i, line in enumerate(section_lines):\n",
        "            match = self.SUBSECTION_PATTERN.match(line)\n",
        "            if match:\n",
        "                sub_matches.append((i, match.group(1), match.group(2)))\n",
        "        \n",
        "        for idx, (rel_line, num, title) in enumerate(sub_matches):\n",
        "            abs_start = base_line + rel_line\n",
        "            if idx + 1 < len(sub_matches):\n",
        "                abs_end = base_line + sub_matches[idx + 1][0] - 1\n",
        "            else:\n",
        "                abs_end = end_line\n",
        "            \n",
        "            sub_content = '\\\\n'.join(self.lines[abs_start - 1:abs_end])\n",
        "            subsections.append(ManuscriptSubsection(\n",
        "                number=num,\n",
        "                title=title.strip(),\n",
        "                start_line=abs_start,\n",
        "                end_line=abs_end,\n",
        "                content=sub_content\n",
        "            ))\n",
        "        \n",
        "        return subsections\n",
        "    \n",
        "    def get_section(self, section_num: str) -> Optional[ManuscriptSection]:\n",
        "        \"\"\"Get a specific section by Roman numeral.\"\"\"\n",
        "        for section in self.sections:\n",
        "            if section.section_num == section_num:\n",
        "                return section\n",
        "        return None\n",
        "    \n",
        "    def get_lines(self, start: int, end: int) -> str:\n",
        "        \"\"\"Get specific line range (1-indexed, inclusive).\"\"\"\n",
        "        return '\\\\n'.join(self.lines[start - 1:end])\n",
        "    \n",
        "    def get_context_around(self, line: int, context: int = 5) -> Tuple[int, int, str]:\n",
        "        \"\"\"Get context around a specific line.\"\"\"\n",
        "        start = max(1, line - context)\n",
        "        end = min(len(self.lines), line + context)\n",
        "        return start, end, self.get_lines(start, end)\n",
        "    \n",
        "    def summary(self) -> str:\n",
        "        \"\"\"Return a summary of the manuscript structure.\"\"\"\n",
        "        lines = [\"üìö MANUSCRIPT STRUCTURE\\\\n\" + \"=\"*50]\n",
        "        for sec in self.sections:\n",
        "            lines.append(f\"\\\\n## {sec.section_num}. {sec.title}\")\n",
        "            lines.append(f\"   Lines: {sec.start_line}-{sec.end_line}\")\n",
        "            for sub in sec.subsections:\n",
        "                lines.append(f\"   ### {sub.number} {sub.title} (L{sub.start_line}-{sub.end_line})\")\n",
        "        return '\\\\n'.join(lines)\n",
        "\n",
        "\n",
        "# Parse the manuscript\n",
        "manuscript = ManuscriptReader(MANUSCRIPT_CONTENT)\n",
        "print(manuscript.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Deficit Report Data Structures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "@dataclass\n",
        "class DeficitItem:\n",
        "    \"\"\"A single identified deficit in the manuscript.\"\"\"\n",
        "    id: str\n",
        "    section: str\n",
        "    subsection: Optional[str]\n",
        "    line_range: Tuple[int, int]\n",
        "    issue_type: str  # 'mathematical', 'physical', 'logical', 'notational', 'derivation'\n",
        "    severity: str    # 'critical', 'major', 'minor'\n",
        "    tier: int        # 1, 2, or 3\n",
        "    current_solution: str\n",
        "    why_faulty: str\n",
        "    resolution_path: str\n",
        "    requires_calculation: bool\n",
        "    \n",
        "    def to_dict(self) -> dict:\n",
        "        return {\n",
        "            'id': self.id,\n",
        "            'section': self.section,\n",
        "            'subsection': self.subsection,\n",
        "            'line_range': list(self.line_range),\n",
        "            'issue_type': self.issue_type,\n",
        "            'severity': self.severity,\n",
        "            'tier': self.tier,\n",
        "            'current_solution': self.current_solution,\n",
        "            'why_faulty': self.why_faulty,\n",
        "            'resolution_path': self.resolution_path,\n",
        "            'requires_calculation': self.requires_calculation\n",
        "        }\n",
        "\n",
        "@dataclass\n",
        "class DeficitReport:\n",
        "    \"\"\"Complete deficit analysis report.\"\"\"\n",
        "    manuscript_version: str\n",
        "    analysis_timestamp: str\n",
        "    total_sections_analyzed: int\n",
        "    deficits: List[DeficitItem] = field(default_factory=list)\n",
        "    \n",
        "    def add_deficit(self, item: DeficitItem):\n",
        "        self.deficits.append(item)\n",
        "    \n",
        "    def get_by_severity(self, severity: str) -> List[DeficitItem]:\n",
        "        return [d for d in self.deficits if d.severity == severity]\n",
        "    \n",
        "    def get_requiring_calculation(self) -> List[DeficitItem]:\n",
        "        return [d for d in self.deficits if d.requires_calculation]\n",
        "    \n",
        "    def to_json(self) -> str:\n",
        "        return json.dumps({\n",
        "            'manuscript_version': self.manuscript_version,\n",
        "            'analysis_timestamp': self.analysis_timestamp,\n",
        "            'total_sections_analyzed': self.total_sections_analyzed,\n",
        "            'summary': {\n",
        "                'total_deficits': len(self.deficits),\n",
        "                'critical': len(self.get_by_severity('critical')),\n",
        "                'major': len(self.get_by_severity('major')),\n",
        "                'minor': len(self.get_by_severity('minor')),\n",
        "                'requiring_calculation': len(self.get_requiring_calculation())\n",
        "            },\n",
        "            'deficits': [d.to_dict() for d in self.deficits]\n",
        "        }, indent=2)\n",
        "    \n",
        "    def display_summary(self):\n",
        "        print(\"\\\\n\" + \"=\"*60)\n",
        "        print(\"üìã DEFICIT REPORT SUMMARY\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"Manuscript: {self.manuscript_version}\")\n",
        "        print(f\"Analyzed: {self.analysis_timestamp}\")\n",
        "        print(f\"Sections analyzed: {self.total_sections_analyzed}\")\n",
        "        print(f\"\\\\nTotal deficits: {len(self.deficits)}\")\n",
        "        print(f\"  üî¥ Critical: {len(self.get_by_severity('critical'))}\")\n",
        "        print(f\"  üü† Major: {len(self.get_by_severity('major'))}\")\n",
        "        print(f\"  üü° Minor: {len(self.get_by_severity('minor'))}\")\n",
        "        print(f\"  üî¢ Requiring calculation: {len(self.get_requiring_calculation())}\")\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Resolution:\n",
        "    \"\"\"A verified resolution for a deficit.\"\"\"\n",
        "    deficit_id: str\n",
        "    resolved_content: str\n",
        "    calculation_log: Optional[str]\n",
        "    verification_passed: bool\n",
        "    self_review_notes: str\n",
        "    \n",
        "    def to_dict(self) -> dict:\n",
        "        return {\n",
        "            'deficit_id': self.deficit_id,\n",
        "            'resolved_content': self.resolved_content,\n",
        "            'calculation_log': self.calculation_log,\n",
        "            'verification_passed': self.verification_passed,\n",
        "            'self_review_notes': self.self_review_notes\n",
        "        }\n",
        "\n",
        "print(\"‚úÖ Data structures defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# ü§ñ AGENT 1: Analyzer\n",
        "\n",
        "**Role:** Reads v68 at every checkpoint, produces detailed technical deficit report with exact locations.\n",
        "\n",
        "**Constraints:**\n",
        "- No ad hoc postulates in resolution paths\n",
        "- No circular reasoning\n",
        "- Must specify exact section, subsection, and line ranges\n",
        "- Must explain WHY current solution is faulty\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "class Agent1_Analyzer:\n",
        "    \"\"\"\n",
        "    Agent 1: Constructive Analyzer\n",
        "    \n",
        "    Reads the manuscript at every checkpoint and produces detailed\n",
        "    deficit reports with exact locations.\n",
        "    \"\"\"\n",
        "    \n",
        "    SYSTEM_INSTRUCTION = \"\"\"\n",
        "You are the **Constructive Analyzer** for the Intrinsic Resonance Holography (IRH) theory.\n",
        "\n",
        "Your role is to perform rigorous analysis of the manuscript and identify deficits that require correction.\n",
        "\n",
        "## Analysis Framework\n",
        "\n",
        "For each section, you must:\n",
        "1. **Mathematical Verification**: Check all equations, derivations, and numerical results\n",
        "2. **Physical Interpretation**: Verify dimensional consistency and physical meaning\n",
        "3. **Logical Flow**: Identify gaps in reasoning or circular arguments\n",
        "4. **Notational Consistency**: Check symbol usage across the manuscript\n",
        "5. **Comparison to Experiment**: Validate numerical predictions against known values\n",
        "\n",
        "## Validation Tiers\n",
        "- **Tier 1**: Predictions within 0.1% of experimental values (precision regime)\n",
        "- **Tier 2**: Predictions within 1% of experimental values (accuracy regime)\n",
        "- **Tier 3**: Predictions within 10% of experimental values (order of magnitude)\n",
        "\n",
        "## Output Format\n",
        "\n",
        "For each deficit found, provide a JSON object with:\n",
        "```json\n",
        "{\n",
        "  \\\"id\\\": \\\"DEF-SEC-NNN\\\",\n",
        "  \\\"section\\\": \\\"Roman numeral\\\",\n",
        "  \\\"subsection\\\": \\\"X.Y or null\\\",\n",
        "  \\\"line_range\\\": [start, end],\n",
        "  \\\"issue_type\\\": \\\"mathematical|physical|logical|notational|derivation\\\",\n",
        "  \\\"severity\\\": \\\"critical|major|minor\\\",\n",
        "  \\\"tier\\\": 1|2|3,\n",
        "  \\\"current_solution\\\": \\\"What the manuscript currently says\\\",\n",
        "  \\\"why_faulty\\\": \\\"Detailed explanation of the problem\\\",\n",
        "  \\\"resolution_path\\\": \\\"How to fix WITHOUT ad hoc postulates or circular reasoning\\\",\n",
        "  \\\"requires_calculation\\\": true|false\n",
        "}\n",
        "```\n",
        "\n",
        "## Critical Constraints\n",
        "\n",
        "1. **NO AD HOC POSTULATES**: Resolution paths must derive from existing axioms\n",
        "2. **NO CIRCULAR REASONING**: Cannot assume what you're trying to prove\n",
        "3. **EXACT LOCATIONS**: Must specify precise line numbers\n",
        "4. **CONSTRUCTIVE CRITICISM**: Focus on how to improve, not just what's wrong\n",
        "\n",
        "Return your analysis as a JSON array of deficit objects.\n",
        "\"\"\"\n",
        "    \n",
        "    def __init__(self, manuscript: ManuscriptReader):\n",
        "        self.manuscript = manuscript\n",
        "        self.model = genai.GenerativeModel(\n",
        "            model_name='gemini-2.5-pro-preview-05-06',\n",
        "            system_instruction=self.SYSTEM_INSTRUCTION\n",
        "        )\n",
        "        self.deficit_report = DeficitReport(\n",
        "            manuscript_version='v68',\n",
        "            analysis_timestamp=datetime.now().isoformat(),\n",
        "            total_sections_analyzed=0\n",
        "        )\n",
        "    \n",
        "    def analyze_section(self, section: ManuscriptSection) -> List[DeficitItem]:\n",
        "        \"\"\"Analyze a single section and return deficits found.\"\"\"\n",
        "        print(f\"\\\\nüî¨ Analyzing Section {section.section_num}: {section.title}\")\n",
        "        print(f\"   Lines: {section.start_line}-{section.end_line}\")\n",
        "        \n",
        "        # Re-read the full manuscript for context at each checkpoint\n",
        "        full_context = f\"\"\"\n",
        "=== FULL MANUSCRIPT (for reference) ===\n",
        "{self.manuscript.raw_content}\n",
        "\n",
        "=== SECTION TO ANALYZE ===\n",
        "Section: {section.section_num}. {section.title}\n",
        "Lines: {section.start_line} to {section.end_line}\n",
        "\n",
        "{section.content}\n",
        "\n",
        "=== TASK ===\n",
        "Analyze this section for deficits. Return a JSON array of deficit objects.\n",
        "If no deficits are found, return an empty array: []\n",
        "\"\"\"\n",
        "        \n",
        "        try:\n",
        "            response = self.model.generate_content(full_context)\n",
        "            \n",
        "            # Parse JSON from response\n",
        "            text = response.text\n",
        "            # Extract JSON array\n",
        "            json_match = re.search(r'\\\\[.*\\\\]', text, re.DOTALL)\n",
        "            if json_match:\n",
        "                deficits_data = json.loads(json_match.group())\n",
        "            else:\n",
        "                print(f\"   ‚ÑπÔ∏è No deficits found in section {section.section_num}\")\n",
        "                return []\n",
        "            \n",
        "            deficits = []\n",
        "            for d in deficits_data:\n",
        "                item = DeficitItem(\n",
        "                    id=d.get('id', f'DEF-{section.section_num}-{len(deficits)+1:03d}'),\n",
        "                    section=d.get('section', section.section_num),\n",
        "                    subsection=d.get('subsection'),\n",
        "                    line_range=tuple(d.get('line_range', [section.start_line, section.end_line])),\n",
        "                    issue_type=d.get('issue_type', 'unknown'),\n",
        "                    severity=d.get('severity', 'minor'),\n",
        "                    tier=d.get('tier', 3),\n",
        "                    current_solution=d.get('current_solution', ''),\n",
        "                    why_faulty=d.get('why_faulty', ''),\n",
        "                    resolution_path=d.get('resolution_path', ''),\n",
        "                    requires_calculation=d.get('requires_calculation', False)\n",
        "                )\n",
        "                deficits.append(item)\n",
        "                self.deficit_report.add_deficit(item)\n",
        "            \n",
        "            print(f\"   ‚úÖ Found {len(deficits)} deficit(s)\")\n",
        "            return deficits\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ùå Error analyzing section: {e}\")\n",
        "            return []\n",
        "    \n",
        "    def run_full_analysis(self) -> DeficitReport:\n",
        "        \"\"\"Run analysis on all sections.\"\"\"\n",
        "        print(\"\\\\n\" + \"=\"*60)\n",
        "        print(\"üöÄ AGENT 1: Starting Full Manuscript Analysis\")\n",
        "        print(\"=\"*60)\n",
        "        \n",
        "        for section in self.manuscript.sections:\n",
        "            self.analyze_section(section)\n",
        "            self.deficit_report.total_sections_analyzed += 1\n",
        "            time.sleep(1)  # Rate limiting\n",
        "        \n",
        "        self.deficit_report.display_summary()\n",
        "        return self.deficit_report\n",
        "\n",
        "\n",
        "# Initialize Agent 1\n",
        "agent1 = Agent1_Analyzer(manuscript)\n",
        "print(\"‚úÖ Agent 1 (Analyzer) initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run Agent 1 Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Run the full analysis\n",
        "deficit_report = agent1.run_full_analysis()\n",
        "\n",
        "# Save intermediate artifact\n",
        "with open('deficit_report_v68.json', 'w') as f:\n",
        "    f.write(deficit_report.to_json())\n",
        "\n",
        "print(\"\\\\nüìÅ Saved: deficit_report_v68.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Display detailed deficits\n",
        "print(\"\\\\n\" + \"=\"*60)\n",
        "print(\"üìã DETAILED DEFICIT LIST\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for i, d in enumerate(deficit_report.deficits, 1):\n",
        "    severity_icon = {'critical': 'üî¥', 'major': 'üü†', 'minor': 'üü°'}.get(d.severity, '‚ö™')\n",
        "    print(f\"\\\\n{severity_icon} [{d.id}] {d.issue_type.upper()}\")\n",
        "    print(f\"   Section: {d.section}\" + (f\" / {d.subsection}\" if d.subsection else \"\"))\n",
        "    print(f\"   Lines: {d.line_range[0]}-{d.line_range[1]}\")\n",
        "    print(f\"   Severity: {d.severity} | Tier: {d.tier}\")\n",
        "    print(f\"   Current: {d.current_solution[:100]}...\" if len(d.current_solution) > 100 else f\"   Current: {d.current_solution}\")\n",
        "    print(f\"   Problem: {d.why_faulty[:150]}...\" if len(d.why_faulty) > 150 else f\"   Problem: {d.why_faulty}\")\n",
        "    print(f\"   Resolution: {d.resolution_path[:150]}...\" if len(d.resolution_path) > 150 else f\"   Resolution: {d.resolution_path}\")\n",
        "    if d.requires_calculation:\n",
        "        print(\"   üî¢ Requires verified calculation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üîß AGENT 2: Resolution Agent\n",
        "\n",
        "**Role:** Receives manuscript + deficit report, uses code execution for verified calculations, self-reviews work.\n",
        "\n",
        "**Capabilities:**\n",
        "- Code execution for numerical verification\n",
        "- Symbolic mathematics with SymPy\n",
        "- Self-review before submitting resolutions\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "class Agent2_Resolution:\n",
        "    \"\"\"\n",
        "    Agent 2: Resolution Agent\n",
        "    \n",
        "    Receives deficit report, generates verified resolutions using\n",
        "    code execution, and performs self-review.\n",
        "    \"\"\"\n",
        "    \n",
        "    SYSTEM_INSTRUCTION = \"\"\"\n",
        "You are the **Resolution Agent** for the Intrinsic Resonance Holography (IRH) theory.\n",
        "\n",
        "Your role is to generate verified resolutions for identified deficits.\n",
        "\n",
        "## Resolution Process\n",
        "\n",
        "For each deficit:\n",
        "1. **Understand Context**: Read the full manuscript section where the deficit occurs\n",
        "2. **Verify the Problem**: Confirm the deficit analysis is correct\n",
        "3. **Generate Resolution**: Create corrected content that fixes the issue\n",
        "4. **Execute Calculations**: For mathematical deficits, provide Python code to verify\n",
        "5. **Self-Review**: Check your resolution before submitting\n",
        "\n",
        "## Code Execution Guidelines\n",
        "\n",
        "When calculations are needed, provide executable Python code using:\n",
        "- `numpy` for numerical computation\n",
        "- `sympy` for symbolic mathematics\n",
        "- `scipy` for scientific functions\n",
        "\n",
        "## Output Format\n",
        "\n",
        "For each resolution, provide:\n",
        "```json\n",
        "{\n",
        "  \\\"deficit_id\\\": \\\"DEF-XXX-NNN\\\",\n",
        "  \\\"resolved_content\\\": \\\"The corrected text/equations to replace the faulty content\\\",\n",
        "  \\\"calculation_code\\\": \\\"Python code to verify (if applicable)\\\",\n",
        "  \\\"calculation_result\\\": \\\"Expected output from the code\\\",\n",
        "  \\\"self_review\\\": {\n",
        "    \\\"mathematically_sound\\\": true|false,\n",
        "    \\\"no_ad_hoc\\\": true|false,\n",
        "    \\\"no_circular_reasoning\\\": true|false,\n",
        "    \\\"dimensionally_consistent\\\": true|false,\n",
        "    \\\"notes\\\": \\\"Any additional review notes\\\"\n",
        "  }\n",
        "}\n",
        "```\n",
        "\n",
        "## Critical Constraints\n",
        "\n",
        "1. All calculations must be VERIFIED with actual code execution\n",
        "2. No hand-wavy approximations without explicit justification\n",
        "3. Maintain the manuscript's notation and style\n",
        "4. Preserve the logical flow of the argument\n",
        "\"\"\"\n",
        "\n",
        "    def __init__(self, manuscript: ManuscriptReader, deficit_report: DeficitReport):\n",
        "        self.manuscript = manuscript\n",
        "        self.deficit_report = deficit_report\n",
        "        self.model = genai.GenerativeModel(\n",
        "            model_name='gemini-2.5-pro-preview-05-06',\n",
        "            system_instruction=self.SYSTEM_INSTRUCTION,\n",
        "            tools='code_execution'\n",
        "        )\n",
        "        self.resolutions: List[Resolution] = []\n",
        "    \n",
        "    def resolve_deficit(self, deficit: DeficitItem) -> Optional[Resolution]:\n",
        "        \"\"\"Generate a verified resolution for a single deficit.\"\"\"\n",
        "        print(f\"\\\\nüîß Resolving [{deficit.id}]: {deficit.issue_type}\")\n",
        "        print(f\"   Section: {deficit.section}, Lines: {deficit.line_range}\")\n",
        "        \n",
        "        # Get relevant manuscript context\n",
        "        section = self.manuscript.get_section(deficit.section)\n",
        "        if not section:\n",
        "            print(f\"   ‚ùå Could not find section {deficit.section}\")\n",
        "            return None\n",
        "        \n",
        "        # Get the specific lines\n",
        "        context_start = max(1, deficit.line_range[0] - 10)\n",
        "        context_end = min(len(self.manuscript.lines), deficit.line_range[1] + 10)\n",
        "        local_context = self.manuscript.get_lines(context_start, context_end)\n",
        "        \n",
        "        prompt = f\"\"\"\n",
        "=== FULL MANUSCRIPT (for reference) ===\n",
        "{self.manuscript.raw_content}\n",
        "\n",
        "=== DEFICIT TO RESOLVE ===\n",
        "{json.dumps(deficit.to_dict(), indent=2)}\n",
        "\n",
        "=== LOCAL CONTEXT (Lines {context_start}-{context_end}) ===\n",
        "{local_context}\n",
        "\n",
        "=== TASK ===\n",
        "Generate a verified resolution for this deficit.\n",
        "{\"Use code execution to verify any calculations.\" if deficit.requires_calculation else \"\"}\n",
        "\n",
        "Return your resolution as a JSON object.\n",
        "\"\"\"\n",
        "        \n",
        "        try:\n",
        "            response = self.model.generate_content(prompt)\n",
        "            \n",
        "            # Extract resolution from response\n",
        "            text = response.text\n",
        "            json_match = re.search(r'\\\\{.*?\\\\}', text, re.DOTALL)\n",
        "            \n",
        "            if json_match:\n",
        "                resolution_data = json.loads(json_match.group())\n",
        "            else:\n",
        "                print(f\"   ‚ö†Ô∏è Could not parse resolution JSON\")\n",
        "                # Use the raw response as resolution\n",
        "                resolution_data = {\n",
        "                    'resolved_content': text,\n",
        "                    'self_review': {'notes': 'Auto-extracted from response'}\n",
        "                }\n",
        "            \n",
        "            # Extract calculation log from code execution\n",
        "            calc_log = None\n",
        "            if hasattr(response, 'candidates') and response.candidates:\n",
        "                for part in response.candidates[0].content.parts:\n",
        "                    if hasattr(part, 'executable_code'):\n",
        "                        calc_log = part.executable_code.code\n",
        "                    if hasattr(part, 'code_execution_result'):\n",
        "                        if calc_log:\n",
        "                            calc_log += f\"\\\\n\\\\n# Output:\\\\n{part.code_execution_result.output}\"\n",
        "            \n",
        "            # Determine verification status\n",
        "            self_review = resolution_data.get('self_review', {})\n",
        "            verification_passed = all([\n",
        "                self_review.get('mathematically_sound', True),\n",
        "                self_review.get('no_ad_hoc', True),\n",
        "                self_review.get('no_circular_reasoning', True),\n",
        "                self_review.get('dimensionally_consistent', True)\n",
        "            ])\n",
        "            \n",
        "            resolution = Resolution(\n",
        "                deficit_id=deficit.id,\n",
        "                resolved_content=resolution_data.get('resolved_content', ''),\n",
        "                calculation_log=calc_log,\n",
        "                verification_passed=verification_passed,\n",
        "                self_review_notes=json.dumps(self_review)\n",
        "            )\n",
        "            \n",
        "            self.resolutions.append(resolution)\n",
        "            \n",
        "            status = \"‚úÖ PASSED\" if verification_passed else \"‚ö†Ô∏è NEEDS REVIEW\"\n",
        "            print(f\"   {status}\")\n",
        "            \n",
        "            return resolution\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ùå Error resolving deficit: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def run_all_resolutions(self) -> List[Resolution]:\n",
        "        \"\"\"Resolve all deficits in the report.\"\"\"\n",
        "        print(\"\\\\n\" + \"=\"*60)\n",
        "        print(\"üöÄ AGENT 2: Starting Resolution Process\")\n",
        "        print(\"=\"*60)\n",
        "        \n",
        "        # Prioritize by severity\n",
        "        sorted_deficits = sorted(\n",
        "            self.deficit_report.deficits,\n",
        "            key=lambda d: {'critical': 0, 'major': 1, 'minor': 2}.get(d.severity, 3)\n",
        "        )\n",
        "        \n",
        "        # Configurable exponential backoff for pacing/API rate limiting\n",
        "        import os\n",
        "        base_delay = float(os.getenv(\"GEMINI_RATE_LIMIT_BASE_DELAY_SECONDS\", \"1.0\"))\n",
        "        max_delay = float(os.getenv(\"GEMINI_RATE_LIMIT_MAX_DELAY_SECONDS\", \"8.0\"))\n",
        "        current_delay = base_delay\n",
        "        \n",
        "        for deficit in sorted_deficits:\n",
        "            self.resolve_deficit(deficit)\n",
        "            # Exponential backoff between resolutions to help respect API rate limits\n",
        "            if current_delay > 0:\n",
        "                time.sleep(current_delay)\n",
        "                current_delay = min(current_delay * 2, max_delay)\n",
        "        \n",
        "        # Summary\n",
        "        passed = sum(1 for r in self.resolutions if r.verification_passed)\n",
        "        print(f\"\\\\n\" + \"=\"*60)\n",
        "        print(f\"üìä Resolution Summary: {passed}/{len(self.resolutions)} verified\")\n",
        "        print(\"=\"*60)\n",
        "        \n",
        "        return self.resolutions\n",
        "\n",
        "\n",
        "# Initialize Agent 2 (requires deficit report from Agent 1)\n",
        "print(\"‚úÖ Agent 2 (Resolution) class defined\")\n",
        "print(\"   Run after Agent 1 completes analysis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run Agent 2 Resolutions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Initialize and run Agent 2\n",
        "agent2 = Agent2_Resolution(manuscript, deficit_report)\n",
        "resolutions = agent2.run_all_resolutions()\n",
        "\n",
        "# Save intermediate artifact\n",
        "with open('resolutions_v68.json', 'w') as f:\n",
        "    json.dump([r.to_dict() for r in resolutions], f, indent=2)\n",
        "\n",
        "print(\"\\\\nüìÅ Saved: resolutions_v68.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Display resolution details\n",
        "print(\"\\\\n\" + \"=\"*60)\n",
        "print(\"üìã RESOLUTION DETAILS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for r in resolutions:\n",
        "    status = \"‚úÖ\" if r.verification_passed else \"‚ö†Ô∏è\"\n",
        "    print(f\"\\\\n{status} [{r.deficit_id}]\")\n",
        "    print(f\"   Content preview: {r.resolved_content[:200]}...\" if len(r.resolved_content) > 200 else f\"   Content: {r.resolved_content}\")\n",
        "    if r.calculation_log:\n",
        "        print(f\"   üìä Calculation verified with code execution\")\n",
        "    print(f\"   Self-review: {r.self_review_notes[:100]}...\" if len(r.self_review_notes) > 100 else f\"   Self-review: {r.self_review_notes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üîÄ AGENT 3: Integration Agent\n",
        "\n",
        "**Role:** Takes resolutions + report + manuscript, writes seamlessly into updated paper.\n",
        "\n",
        "**Workflow:**\n",
        "1. Apply resolutions to manuscript\n",
        "2. Ensure seamless integration\n",
        "3. **PAUSE for user approval**\n",
        "4. Output IRHv69.md\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "class Agent3_Integration:\n",
        "    \"\"\"\n",
        "    Agent 3: Integration Agent\n",
        "    \n",
        "    Takes resolutions and integrates them seamlessly into the manuscript.\n",
        "    Pauses for user approval before finalizing.\n",
        "    \"\"\"\n",
        "    \n",
        "    SYSTEM_INSTRUCTION = \"\"\"\n",
        "You are the **Integration Agent** for the Intrinsic Resonance Holography (IRH) theory.\n",
        "\n",
        "Your role is to integrate verified resolutions seamlessly into the manuscript.\n",
        "\n",
        "## Integration Guidelines\n",
        "\n",
        "1. **Preserve Voice**: Maintain the manuscript's academic writing style\n",
        "2. **Smooth Transitions**: Ensure edits flow naturally with surrounding text\n",
        "3. **Notation Consistency**: Use the same symbols and conventions throughout\n",
        "4. **Cross-References**: Update any references to changed content\n",
        "5. **Version Clarity**: The output is v69, building on v68\n",
        "\n",
        "## Output Format\n",
        "\n",
        "Return the complete updated manuscript with all resolutions integrated.\n",
        "Mark significant changes with HTML comments: <!-- v69: [description] -->\n",
        "\n",
        "## Quality Checks\n",
        "\n",
        "Before finalizing, verify:\n",
        "- All deficits have been addressed\n",
        "- No orphaned references\n",
        "- Consistent equation numbering\n",
        "- Proper section/subsection structure maintained\n",
        "\"\"\"\n",
        "\n",
        "    def __init__(self, manuscript: ManuscriptReader, deficit_report: DeficitReport, resolutions: List[Resolution]):\n",
        "        self.manuscript = manuscript\n",
        "        self.deficit_report = deficit_report\n",
        "        self.resolutions = resolutions\n",
        "        self.model = genai.GenerativeModel(\n",
        "            model_name='gemini-2.5-pro-preview-05-06',\n",
        "            system_instruction=self.SYSTEM_INSTRUCTION\n",
        "        )\n",
        "        self.updated_manuscript = None\n",
        "        self.change_log = []\n",
        "    \n",
        "    def prepare_integration_prompt(self) -> str:\n",
        "        \"\"\"Prepare the prompt for integration.\"\"\"\n",
        "        resolution_summary = []\n",
        "        for r in self.resolutions:\n",
        "            # Find matching deficit\n",
        "            deficit = next((d for d in self.deficit_report.deficits if d.id == r.deficit_id), None)\n",
        "            if deficit:\n",
        "                resolution_summary.append({\n",
        "                    'deficit_id': r.deficit_id,\n",
        "                    'section': deficit.section,\n",
        "                    'subsection': deficit.subsection,\n",
        "                    'line_range': deficit.line_range,\n",
        "                    'original_issue': deficit.current_solution,\n",
        "                    'resolved_content': r.resolved_content,\n",
        "                    'verified': r.verification_passed\n",
        "                })\n",
        "        \n",
        "        return f\"\"\"\n",
        "=== ORIGINAL MANUSCRIPT (v68) ===\n",
        "{self.manuscript.raw_content}\n",
        "\n",
        "=== RESOLUTIONS TO INTEGRATE ===\n",
        "{json.dumps(resolution_summary, indent=2)}\n",
        "\n",
        "=== TASK ===\n",
        "Integrate all resolutions into the manuscript to create v69.\n",
        "Return the COMPLETE updated manuscript with all changes applied.\n",
        "Use <!-- v69: description --> comments to mark significant changes.\n",
        "\"\"\"\n",
        "    \n",
        "    def generate_updated_manuscript(self) -> str:\n",
        "        \"\"\"Generate the updated manuscript with all resolutions integrated.\"\"\"\n",
        "        print(\"\\\\n\" + \"=\"*60)\n",
        "        print(\"üöÄ AGENT 3: Starting Integration Process\")\n",
        "        print(\"=\"*60)\n",
        "        \n",
        "        print(f\"\\\\nüìù Integrating {len(self.resolutions)} resolution(s)...\")\n",
        "        \n",
        "        prompt = self.prepare_integration_prompt()\n",
        "        \n",
        "        try:\n",
        "            response = self.model.generate_content(prompt)\n",
        "            self.updated_manuscript = response.text\n",
        "            \n",
        "            # Log changes\n",
        "            for r in self.resolutions:\n",
        "                self.change_log.append({\n",
        "                    'deficit_id': r.deficit_id,\n",
        "                    'verified': r.verification_passed\n",
        "                })\n",
        "            \n",
        "            print(f\"\\\\n‚úÖ Integration complete\")\n",
        "            print(f\"   Original length: {len(self.manuscript.raw_content):,} chars\")\n",
        "            print(f\"   Updated length: {len(self.updated_manuscript):,} chars\")\n",
        "            \n",
        "            return self.updated_manuscript\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"\\\\n‚ùå Error during integration: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def display_preview(self, lines: int = 100):\n",
        "        \"\"\"Display a preview of the updated manuscript.\"\"\"\n",
        "        if not self.updated_manuscript:\n",
        "            print(\"‚ö†Ô∏è No updated manuscript available. Run generate_updated_manuscript() first.\")\n",
        "            return\n",
        "        \n",
        "        preview_lines = self.updated_manuscript.splitlines()[:lines]\n",
        "        print(\"\\\\n\" + \"=\"*60)\n",
        "        print(f\"üìÑ PREVIEW (first {lines} lines)\")\n",
        "        print(\"=\"*60 + \"\\\\n\")\n",
        "        print('\\\\n'.join(preview_lines))\n",
        "        print(\"\\\\n\" + \"=\"*60)\n",
        "        print(f\"... [{len(self.updated_manuscript.splitlines()) - lines} more lines]\")\n",
        "\n",
        "\n",
        "# Initialize Agent 3 (requires resolutions from Agent 2)\n",
        "print(\"‚úÖ Agent 3 (Integration) class defined\")\n",
        "print(\"   Run after Agent 2 completes resolutions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run Agent 3 Integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Initialize and run Agent 3\n",
        "agent3 = Agent3_Integration(manuscript, deficit_report, resolutions)\n",
        "updated_manuscript = agent3.generate_updated_manuscript()\n",
        "\n",
        "# Show preview\n",
        "agent3.display_preview(lines=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# ‚è∏Ô∏è USER APPROVAL CHECKPOINT\n",
        "\n",
        "**Before saving IRHv69.md, please review the changes and approve.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Display change summary for user review\n",
        "print(\"\\\\n\" + \"=\"*60)\n",
        "print(\"üìã CHANGE SUMMARY FOR APPROVAL\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\\\nüìä Statistics:\")\n",
        "print(f\"   Deficits identified: {len(deficit_report.deficits)}\")\n",
        "print(f\"   Resolutions generated: {len(resolutions)}\")\n",
        "verified = sum(1 for r in resolutions if r.verification_passed)\n",
        "print(f\"   Verified resolutions: {verified}/{len(resolutions)}\")\n",
        "\n",
        "print(f\"\\\\nüìù Changes by section:\")\n",
        "sections_changed = {}\n",
        "for d in deficit_report.deficits:\n",
        "    sections_changed[d.section] = sections_changed.get(d.section, 0) + 1\n",
        "for sec, count in sorted(sections_changed.items()):\n",
        "    print(f\"   Section {sec}: {count} change(s)\")\n",
        "\n",
        "print(f\"\\\\n‚ö†Ô∏è Unverified resolutions:\")\n",
        "unverified = [r for r in resolutions if not r.verification_passed]\n",
        "if unverified:\n",
        "    for r in unverified:\n",
        "        print(f\"   - {r.deficit_id}\")\n",
        "else:\n",
        "    print(\"   None - all resolutions verified! ‚úÖ\")\n",
        "\n",
        "print(\"\\\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# USER APPROVAL CHECKPOINT\n",
        "print(\"\\\\n\" + \"üîî\"*20)\n",
        "print(\"\\\\n‚è∏Ô∏è  USER APPROVAL REQUIRED\")\n",
        "print(\"\\\\nReview the changes above. Do you want to save IRHv69.md?\")\n",
        "print(\"\\\\n\" + \"üîî\"*20 + \"\\\\n\")\n",
        "\n",
        "# Prompt for approval\n",
        "approval = input(\"Type 'yes' to approve and save, or 'no' to cancel: \").strip().lower()\n",
        "\n",
        "if approval == 'yes':\n",
        "    APPROVED = True\n",
        "    print(\"\\\\n‚úÖ APPROVED - Proceeding to save IRHv69.md\")\n",
        "else:\n",
        "    APPROVED = False\n",
        "    print(\"\\\\n‚ùå NOT APPROVED - IRHv69.md will NOT be saved\")\n",
        "    print(\"   You can re-run the integration or make manual adjustments.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üíæ Export IRHv69.md\n",
        "\n",
        "**Only runs if user approved in the previous cell.**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "if APPROVED:\n",
        "    # Save the updated manuscript\n",
        "    output_filename = 'IntrinsicResonanceHolography_v69.md'\n",
        "    \n",
        "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "        f.write(updated_manuscript)\n",
        "    \n",
        "    print(f\"\\\\n‚úÖ Saved: {output_filename}\")\n",
        "    print(f\"   Size: {len(updated_manuscript):,} characters\")\n",
        "    print(f\"   Lines: {len(updated_manuscript.splitlines()):,}\")\n",
        "    \n",
        "    # Also save the full pipeline artifacts\n",
        "    pipeline_summary = {\n",
        "        'version': 'v68 ‚Üí v69',\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'deficits_found': len(deficit_report.deficits),\n",
        "        'resolutions_generated': len(resolutions),\n",
        "        'resolutions_verified': verified,\n",
        "        'sections_modified': list(sections_changed.keys()),\n",
        "        'approved': True\n",
        "    }\n",
        "    \n",
        "    with open('v69_pipeline_summary.json', 'w') as f:\n",
        "        json.dump(pipeline_summary, f, indent=2)\n",
        "    \n",
        "    print(f\"\\\\nüìÅ Pipeline summary saved: v69_pipeline_summary.json\")\n",
        "    \n",
        "    # Download files\n",
        "    print(\"\\\\nüì• Downloading files...\")\n",
        "    files.download(output_filename)\n",
        "    files.download('deficit_report_v68.json')\n",
        "    files.download('resolutions_v68.json')\n",
        "    files.download('v69_pipeline_summary.json')\n",
        "    \n",
        "    print(\"\\\\nüéâ Pipeline complete! All files downloaded.\")\n",
        "else:\n",
        "    print(\"\\\\n‚è∏Ô∏è Export skipped - user did not approve.\")\n",
        "    print(\"   Re-run the approval cell when ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# üìä Optional: Detailed Analysis Reports\n",
        "\n",
        "Additional analysis and visualization tools.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Deficit distribution by type and severity\n",
        "print(\"\\\\n\" + \"=\"*60)\n",
        "print(\"üìä DEFICIT ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# By type\n",
        "by_type = {}\n",
        "for d in deficit_report.deficits:\n",
        "    by_type[d.issue_type] = by_type.get(d.issue_type, 0) + 1\n",
        "\n",
        "print(\"\\\\nBy Issue Type:\")\n",
        "for t, count in sorted(by_type.items(), key=lambda x: -x[1]):\n",
        "    bar = '‚ñà' * count\n",
        "    print(f\"  {t:15} {bar} ({count})\")\n",
        "\n",
        "# By tier\n",
        "by_tier = {}\n",
        "for d in deficit_report.deficits:\n",
        "    by_tier[d.tier] = by_tier.get(d.tier, 0) + 1\n",
        "\n",
        "print(\"\\\\nBy Validation Tier:\")\n",
        "tier_labels = {1: 'Tier 1 (<0.1%)', 2: 'Tier 2 (<1%)', 3: 'Tier 3 (<10%)'}\n",
        "for t in [1, 2, 3]:\n",
        "    count = by_tier.get(t, 0)\n",
        "    bar = '‚ñà' * count\n",
        "    print(f\"  {tier_labels[t]:15} {bar} ({count})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
        "# Show calculation logs from verified resolutions\n",
        "print(\"\\\\n\" + \"=\"*60)\n",
        "print(\"üî¢ CALCULATION LOGS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for r in resolutions:\n",
        "    if r.calculation_log:\n",
        "        print(f\"\\\\n--- {r.deficit_id} ---\")\n",
        "        print(r.calculation_log[:500])\n",
        "        if len(r.calculation_log) > 500:\n",
        "            print(f\"... [{len(r.calculation_log) - 500} more characters]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìù Session Notes\n",
        "\n",
        "**Pipeline Version:** 1.0  \n",
        "**Target Repository:** brandonmccraryresearch-cloud/IRHV24  \n",
        "**Notebook for PR:** IRHv68_MultiAgent_Verification.ipynb\n",
        "\n",
        "### Changelog\n",
        "- v1.0: Initial three-agent architecture (Analyzer ‚Üí Resolution ‚Üí Integration)\n",
        "\n",
        "---"
      ]
    }
  ]
}